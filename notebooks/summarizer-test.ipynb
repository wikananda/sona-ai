{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb95bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22079268",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d244ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "from summarization import SummarizationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef32addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CausalLM base model from meta-llama/Llama-3.2-3B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [32:28<00:00, 974.11s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying new LoRA configuration (task_type=CAUSAL_LM)...\n",
      "Using device: mps\n",
      "Task type: causal\n",
      "trainable params: 2,293,760 || all params: 3,215,043,584 || trainable%: 0.0713\n",
      "Preparing dataset...\n",
      "Loading processed dataset from disk...\n",
      "Failed to load dataset from disk. Tokenizing dataset...\n",
      "Train size: 100 | Val size: 10 | Test size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 186.92 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 168.30 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 189.15 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 51839.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 5881.79 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 5803.66 examples/s]\n",
      "/Users/komangwikananda/Documents/Work/Sona AI/sona-ai/summarization/SummarizationTrainer.py:89: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging custom training arguments...\n",
      "Warning: Unused arguments: ['predict_with_generate', 'generation_max_length', 'generation_num_beams']\n"
     ]
    }
   ],
   "source": [
    "training_args = {\n",
    "    # ===== TRAINING =====\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "\n",
    "    # ===== EVALUATION / LOGGING / SAVING =====\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"logging_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "\n",
    "    # ===== SEQ2SEQ SPECIFIC =====\n",
    "    \"predict_with_generate\": True,\n",
    "    \"generation_max_length\": 256,\n",
    "    \"generation_num_beams\": 4,\n",
    "\n",
    "    # ===== PERFORMANCE =====\n",
    "    \"fp16\": False,\n",
    "    \"gradient_checkpointing\": True,\n",
    "\n",
    "    # ===== MODEL SELECTION =====\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"rougeL\",\n",
    "    \"greater_is_better\": True,\n",
    "\n",
    "    # ===== MISC =====\n",
    "    \"report_to\": \"none\",\n",
    "\n",
    "    # REQUIRED\n",
    "    \"output_dir\": \"../outputs/summarization\",\n",
    "}\n",
    "\n",
    "\n",
    "trainer = SummarizationTrainer(config=\"llama\")\n",
    "trainer.prepare_data_and_trainer(\n",
    "    training_args_dict=training_args,\n",
    "    train_size=100,\n",
    "    val_size=10,\n",
    "    test_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374453d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc429e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2266db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/komangwikananda/miniconda3/envs/sona-ai/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/komangwikananda/miniconda3/envs/sona-ai/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "from summarization import SummarizationInferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b707f0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nik: I don't think we should apply this change. \n",
      "Ren: I agree. The helmet make the side ears looks too small. The face proportion looks weird. \n",
      "Nik: But, I like the helmet tho. It looks kinda nice. \n",
      "Ren: Should I redraw and adjust this? So we can keep it. \n",
      "Nik: Yeah, I really think wearing a helmet will make this character looks awesome. It is just this helmet is not suitable for him. But, the design is cool tho. Maybe for the other character. \n",
      "Ren: Yeah, sure. I will redraw it, then I will comeback to you later. \n",
      "Nik: Ok, sure.\n"
     ]
    }
   ],
   "source": [
    "text = f\"Nik: I don't think we should apply this change. \\nRen: I agree. The helmet make the side ears looks too small. The face proportion looks weird. \\nNik: But, I like the helmet tho. It looks kinda nice. \\nRen: Should I redraw and adjust this? So we can keep it. \\nNik: Yeah, I really think wearing a helmet will make this character looks awesome. It is just this helmet is not suitable for him. But, the design is cool tho. Maybe for the other character. \\nRen: Yeah, sure. I will redraw it, then I will comeback to you later. \\nNik: Ok, sure.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1284cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert meeting analyst.Extract structured information from the conversation.\n",
      "Output format:\n",
      "Topics:\n",
      "- item\n",
      "\n",
      "Concerns:\n",
      "- item\n",
      "\n",
      "Solutions:\n",
      "- item\n",
      "\n",
      "Next Steps:\n",
      "- item\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_prompt = (\n",
    "\"You are an expert meeting analyst.\"\n",
    "\"Extract structured information from the conversation.\\n\"\n",
    "\"Output format:\\n\"\n",
    "\"Topics:\\n\"\n",
    "\"- item\\n\\n\"\n",
    "\"Concerns:\\n\"\n",
    "\"- item\\n\\n\"\n",
    "\"Solutions:\\n\"\n",
    "\"- item\\n\\n\"\n",
    "\"Next Steps:\\n\"\n",
    "\"- item\\n\\n\"\n",
    ")\n",
    "print(custom_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd2169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CausalLM base model from meta-llama/Llama-3.2-3B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Task type: causal\n",
      " Nik and Ren are discussing the design of a character. Nik wants to apply the change, but Ren is concerned that the helmet makes the character's side ears look too small and the face proportions look weird. Nik likes the helmet but thinks it doesn't suit the character. Ren agrees to redraw the helmet and come back to Nik later to show the revised design.\n",
      "\n",
      "\n",
      "\n",
      "Structured Information:\n",
      "\n",
      "Topics:\n",
      "• Character design\n",
      "• Helmet design\n",
      " \n",
      "\n",
      " Concerns:\n",
      "• Helmet size and proportion\n",
      "• Face proportions\n",
      " \n",
      "\n",
      " Solutions:\n",
      "• Redraw the helmet\n",
      "• Revise the character design\n",
      "\n",
      " Next Steps:\n",
      "• Ren to redraw and revisit the design with Nik\n",
      "• Nik to review and provide feedback to Ren\n"
     ]
    }
   ],
   "source": [
    "inferencer = SummarizationInferencer(\n",
    "    config=\"llama\",\n",
    "    base_model=True,\n",
    "    use_pretrained=True,\n",
    "    device=\"cpu\",\n",
    "    max_new_tokens=256,\n",
    "    num_beams=4,\n",
    ")\n",
    "summary = inferencer.generate(text, prompt=custom_prompt, max_length=256)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db1696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sona-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
